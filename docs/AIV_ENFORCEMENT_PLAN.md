# AIV Verification Protocol - Enforcement Plan

**Document Version:** 1.1 (SOP Compliance Focus)  
**Target Branch:** `main` (post PR-1 merge)  
**Implementation PR:** PR-2 (AIV Hard Enforcement)  
**Protocol Version:** AIV v2.0 (SOP Mechanical Layer Only)  
**Scope:** Tasks 1-9 Refactor Work  
**SVP Status:** Deferred to Future Work

---

## Executive Summary

This document defines the **SOP compliance enforcement strategy** for the flashcore refactor project (Tasks 1-9). This is a **pragmatic, minimal-friction approach** focused on evidence-based verification without requiring advanced cognitive tooling (SVP).

### Philosophy: Hard on Compliance, Soft on Cognition

For the refactor phase, we enforce:
1. **Packet Gating:** No PR can merge without a complete Verification Packet
2. **CI-First:** Every falsifiable claim must point to a CI run or artifact
3. **Runtime Alignment:** CI must test the actual target runtime (Python >=3.10)
4. **Zero-Touch Preferred:** Verifiers should inspect artifacts, not run code locally (but not strictly forbidden)

We defer to future work:
- Mental Trace requirements (SVP Layer 2)
- Ownership Lock/Commit requirements (SVP Layer 3)
- Verifier ELO tracking and mastery metrics
- Advanced tooling (`aiv-cli`, packet generators)

---

## Current State Analysis

### What Works (Already Compatible)
- ‚úÖ **Atomic work units exist:** `tasks.json` provides task/subtask decomposition
- ‚úÖ **Reproduction instructions exist:** Most tasks have `testStrategy` fields
- ‚úÖ **Intent sources exist:** `docs/PRD.md` + `.taskmaster/tasks/` provide Class E evidence anchors
- ‚úÖ **CI infrastructure exists:** `.github/workflows/main.yml` runs tests on push/PR

### What Blocks SOP Compliance (Enforcement Gaps)
- ‚ùå **PR template is not SOP-shaped:** Generic template, no packet structure
- ‚ùå **CI runtime misalignment:** Runs Python 3.9, but plan requires >=3.10 (Pydantic v2)
- ‚ùå **No artifact production:** CI runs tests but doesn't systematically upload evidence artifacts
- ‚ùå **No packet validation:** No automated check that PR body contains required packet structure

### What We're NOT Enforcing Yet (Future Work)
- ‚è∏Ô∏è **Mental Trace documentation:** Verifiers not required to document cognitive simulation
- ‚è∏Ô∏è **Ownership Commits:** Verifiers not required to make semantic refactoring commits
- ‚è∏Ô∏è **Verifier skill tracking:** No ELO rating or mastery metrics
- ‚è∏Ô∏è **Advanced tooling:** No `aiv-cli` or automated packet generators

---

## Enforcement Architecture

### Phase 0: Protocol Gate (Minimum Viable Enforcement)
**Goal:** No PR can merge without a Verification Packet.

#### Rule 0 (Hard Gate)
Every PR must include `# AIV Verification Packet (v2.1)` in the PR body.

#### Rule 1 (Class E Mandatory)
Packet must include:
- **Task link:** Task Master ID + path to generated task file
- **PRD link:** `docs/PRD.md` section reference

#### Rule 2 (CI First)
Every claim that can be machine-verified must point to a CI run or CI artifact.

#### Rule 3 (Fast-Track Exception)
Permit "Fast-Track (Trivial)" only for:
- Documentation changes (`.md`, `.txt`)
- Configuration changes (`.gitignore`, `.editorconfig`)
- **NOT** functional Python changes

#### Rule 4 (Immutable Intent Links - Addendum 2.2)
Class E (Intent Alignment) links must target:
- Specific commit SHAs (e.g., `blob/a1b2c3d/docs/PRD.md`)
- **NOT** mutable branches (`main`, `master`, `develop`)

**Rationale:** Prevents "intent drift" where documentation changes after implementation.

---

### Phase 1: Evidence Production (Zero-Touch Preferred)
**Goal:** Verifier primarily inspects CI artifacts; local execution allowed but discouraged.

#### Class A (Execution Evidence)
- **Artifact:** `pytest` output (already in logs) + JUnit XML
- **Artifact:** Coverage XML (already generated by `make test`)
- **CI Job:** Upload test results and coverage as GitHub Actions artifacts

#### Class C (Negative Evidence)
- **Artifact:** Output files from `grep`/`rg` commands specified in `testStrategy`
- **Example:** `artifacts/no_cultivation_imports.txt` (proves no legacy imports)
- **CI Job:** Run negative checks and upload output files

#### Class D (State Evidence)
- **Artifact:** Database schema dumps (for DB/schema changes)
- **Example:** DuckDB `.schema` output or `information_schema` query results
- **CI Job:** Run deterministic DB queries and upload output

#### Class F (Conservation Evidence)
- **Artifact:** Full test suite pass (already required)
- **Artifact:** Warning report for deleted assertions/skipped tests (informational only)
- **CI Job:** Scan test file diffs and warn on potential test weakening

**Note:** This is a **soft check** (warning, not failure). Verifier makes final judgment on whether test changes are justified.

---

### Phase 2: Performance Claims Audited (Task 4 Hardening)
**Goal:** Performance improvements require CI A/B proof.

#### For Task 4 (O(1) Scheduler)
- **Required:** Benchmark job that runs baseline vs PR in CI
- **Artifact:** JSON containing both timings + comparison
- **Gate:** Label `perf-critical` required on Task 4 PRs
- **Enforcement:** CI fails if benchmark shows <50% improvement or regression

---

## Claim-Evidence Matrix (Task Category Mapping)

### 1. Build / Packaging / Dependency Constraints (Task 1, 1.x)
**Typical Claims:**
- "Renamed `flashcore-lib` ‚Üí `flashcore`"
- "pyproject.toml is now source of truth"
- "No heavy dependencies"

**Required Evidence:**
- **Class B:** File tree diff / paths (git diff)
- **Class A:** CI install + tests pass
- **Class C:** `pip list | grep torch` (should be empty) captured in CI artifact

---

### 2. Refactors with Invariants (Tasks 2, 3, 5, 6 structural work)
**Required Evidence:**
- **Class C:** Full regression suite pass in CI (proves "No Functional Change")
- **Class B:** Paths/line references for moved modules
- **Class F:** Conservation proof (tests not weakened)

---

### 3. New CLI Behaviors (Task 6.2 configure / config loader)
**Required Evidence:**
- **Class A:** CLI integration tests in CI showing:
  - Works with `--db` flag
  - Works with env/config default
- **Class B:** File/line references showing resolution order implemented

---

### 4. Performance Improvement (Task 4)
**Required Evidence:**
- **Class A:** CI A/B benchmark artifact
- **Class B:** Code pointers to removed history replay and new O(1) logic

---

### 5. State / Migration (Task 8)
**Required Evidence:**
- **Class D:** DB row counts / schema dump as CI artifact
- **Class B:** Migration scripts path + schema definition
- **Bootstrap Exception:** If CI cannot access legacy DB, document manual verification steps

---

## Technical Implementation Plan

### File Changes Required

#### 1. `.github/PULL_REQUEST_TEMPLATE.md`
**Action:** Replace entire file with AIV Packet template.

**New Template Structure:**
```markdown
# AIV Verification Packet (v2.1)

## Claim(s)
<!-- List atomic, falsifiable claims. One claim per line. -->
- 

## Evidence

### Class A (Execution Evidence)
<!-- CI run links, test output artifacts -->
- 

### Class B (Referential Evidence)
<!-- File paths, line numbers, git diff links -->
- 

### Class C (Negative Evidence)
<!-- Grep outputs, absence proofs -->
- 

### Class D (State Evidence)
<!-- DB dumps, schema outputs (if applicable) -->
- N/A

### Class E (Intent Alignment)
<!-- Task Master task link + PRD section reference -->
- Task: `.taskmaster/tasks/task_XXX.md`
- PRD: `docs/PRD.md#section-X`

### Class F (Conservation Evidence)
<!-- Test suite pass, no weakened assertions -->
- CI test suite: [link]

## Reproduction
<!-- Commands or CI workflow that verifier can inspect -->
```

---

#### 2. `.github/workflows/aiv-guard.yml`
**Action:** Create new workflow to validate packet structure.

**Purpose:** Fail PR if packet headers are missing.

**Implementation:**
```yaml
name: AIV Packet Validation

on:
  pull_request:
    types: [opened, edited, synchronize]

jobs:
  validate-packet:
    runs-on: ubuntu-latest
    steps:
      - name: Check PR body for AIV packet
        uses: actions/github-script@v7
        with:
          script: |
            const body = context.payload.pull_request.body || '';
            
            // Required headers
            const required = [
              '# AIV Verification Packet',
              '## Claim(s)',
              '## Evidence',
              '### Class E (Intent Alignment)',
              '## Reproduction'
            ];
            
            const missing = required.filter(h => !body.includes(h));
            
            if (missing.length > 0) {
              core.setFailed(`Missing required packet sections: ${missing.join(', ')}`);
              return;
            }
            
            // Check for immutable Class E links (Addendum 2.2)
            const classEMatch = body.match(/### Class E \(Intent Alignment\)[\s\S]*?(?=###|$)/);
            if (classEMatch) {
              const classESection = classEMatch[0];
              const mutableBranchPattern = /\/blob\/(main|master|develop)\//;
              
              if (mutableBranchPattern.test(classESection)) {
                core.setFailed(
                  '‚ùå Class E links must target commit SHA, not mutable branch (main/master/develop).\n' +
                  'Example: Use `/blob/a1b2c3d/docs/PRD.md` instead of `/blob/main/docs/PRD.md`'
                );
                return;
              }
            }
            
            core.info('‚úÖ AIV Packet structure validated');
            core.info('‚úÖ Class E links are immutable');
```

---

#### 3. `.github/workflows/main.yml`
**Action:** Update existing CI workflow.

**Changes Required:**

##### 3a. Fix Python Version Alignment
**Current:** Runs Python 3.9  
**Required:** Python 3.10+ (Pydantic v2 requirement)

```yaml
# BEFORE
matrix:
  python-version: [3.9]

# AFTER
matrix:
  python-version: ['3.10', '3.11']
```

##### 3b. Add Artifact Uploads (Class A Evidence)
```yaml
- name: Run tests
  run: make test

- name: Upload test results
  if: always()
  uses: actions/upload-artifact@v4
  with:
    name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
    path: |
      htmlcov/
      coverage.xml
      .coverage

- name: Upload coverage to Codecov
  uses: codecov/codecov-action@v3

##### 3e. Add Anti-Cheat Warning (Class F - Soft Check)
```yaml
anti-cheat-warning:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
    
    - name: Check for test weakening
      run: |
        mkdir -p artifacts
        
        # Get diff of test files
        git diff origin/main...HEAD -- 'tests/**/*.py' > test_diff.txt
        
        # Count deleted assert lines
        deleted_asserts=$(grep -c '^-.*assert ' test_diff.txt || true)
        
        # Count added skip decorators
        added_skips=$(grep -c '^+.*@pytest.mark.skip' test_diff.txt || true)
        
        # Generate warning report
        echo "# Anti-Cheat Report (Class F)" > artifacts/anti_cheat_report.txt
        echo "" >> artifacts/anti_cheat_report.txt
        echo "Deleted assertions: $deleted_asserts" >> artifacts/anti_cheat_report.txt
        echo "Added skips: $added_skips" >> artifacts/anti_cheat_report.txt
        echo "" >> artifacts/anti_cheat_report.txt
        
        if [ "$deleted_asserts" -gt 0 ] || [ "$added_skips" -gt 0 ]; then
          echo "‚ö†Ô∏è WARNING: Test weakening detected" >> artifacts/anti_cheat_report.txt
          echo "Verifier must manually confirm this is justified." >> artifacts/anti_cheat_report.txt
          cat artifacts/anti_cheat_report.txt
        else
          echo "‚úÖ No test weakening detected" >> artifacts/anti_cheat_report.txt
        fi
    
    - name: Upload anti-cheat report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: anti-cheat-report
        path: artifacts/anti_cheat_report.txt
```

##### 3c. Add Negative Evidence Job (Class C)
```yaml
negative-checks:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v3
    
    - name: Check for legacy imports
      run: |
        mkdir -p artifacts
        echo "Checking for cultivation.scripts.flashcore imports..."
        if grep -r "from cultivation.scripts.flashcore" flashcore/ 2>/dev/null; then
          echo "‚ùå Found legacy imports" | tee artifacts/legacy_imports_check.txt
          exit 1
        else
          echo "‚úÖ No legacy imports found" | tee artifacts/no_cultivation_imports.txt
        fi
    
    - name: Check for heavy dependencies
      run: |
        pip install -e .
        echo "Checking for torch/transformers..."
        if pip list | grep -E "torch|transformers" > artifacts/heavy_deps_found.txt; then
          echo "‚ö†Ô∏è Heavy dependencies detected" | tee -a artifacts/heavy_deps_found.txt
        else
          echo "‚úÖ No heavy deps" > artifacts/heavy_deps_check.txt
        fi
    
    - name: Upload negative evidence
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: negative-evidence
        path: artifacts/
```

##### 3d. Add State Evidence Job (Class D - for DB changes)
```yaml
schema-validation:
  runs-on: ubuntu-latest
  if: contains(github.event.pull_request.labels.*.name, 'database')
  steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: pip install -e .
    
    - name: Generate schema dump
      run: |
        mkdir -p artifacts
        python -c "
        from flashcore.db.schema import DB_SCHEMA_SQL
        with open('artifacts/schema.sql', 'w') as f:
            f.write(DB_SCHEMA_SQL)
        "
    
    - name: Upload schema artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: schema-dump
        path: artifacts/schema.sql
```

---

#### 4. `.github/workflows/perf-benchmark.yml` (Optional - Task 4 only)
**Action:** Create new workflow for performance claims.

**Trigger:** Only when PR has label `perf-critical`.

**Implementation:**
```yaml
name: Performance Benchmark

on:
  pull_request:
    types: [labeled, synchronize]

jobs:
  benchmark:
    if: contains(github.event.pull_request.labels.*.name, 'perf-critical')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install -e . pytest pytest-benchmark
      
      - name: Run baseline benchmark (main)
        run: |
          git checkout main
          pip install -e .
          pytest tests/test_scheduler.py::test_compute_next_state_benchmark --benchmark-json=baseline.json
      
      - name: Run PR benchmark
        run: |
          git checkout ${{ github.head_ref }}
          pip install -e .
          pytest tests/test_scheduler.py::test_compute_next_state_benchmark --benchmark-json=pr.json
      
      - name: Compare results
        run: |
          python scripts/compare_benchmarks.py baseline.json pr.json > benchmark_comparison.txt
      
      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            baseline.json
            pr.json
            benchmark_comparison.txt
```

---

## Operating Rules for This Branch

### One PR = One Task
- Each PR implements exactly one Task Master task (or one subtask-cluster)
- No mixed intent PRs

### PR Title Convention
- Format: `task-N: <brief description>`
- Example: `task-6: CLI package + config loader`

### Packet Claim Discipline
- Every claim must be **atomic** (single assertion)
- Every claim must be **falsifiable** (can be proven false)
- Claims must map to evidence classes

### Prefer CI Artifacts Over Local Execution
Reproduction evidence should prioritize:
1. **Best:** CI run link or CI artifact link
2. **Acceptable:** Single `make ...` command that verifier can run locally
3. **Discouraged:** Multi-step manual setup ("pull branch, run migrations, start server")

**Rationale:** CI artifacts reduce verifier toil, but we don't strictly forbid local execution for the refactor phase.

---

## Rollout Strategy

### Step 1: PR-2 (AIV Infrastructure)
**Branch:** `process/aiv-enforcement`  
**Changes:**
- Update PR template
- Add `aiv-guard.yml`
- Fix Python version in `main.yml`
- Add artifact uploads to `main.yml`

**Verification:**
- Create a test PR to verify packet validation works
- Verify CI runs on Python 3.10+
- Verify artifacts are uploaded and accessible

---

### Step 2: Soft Enforcement Period (Optional)
**Duration:** 1-2 PRs  
**Goal:** Team learns packet format without hard failures

**Approach:**
- `aiv-guard.yml` runs but doesn't block merge (warning only)
- Reviewer manually checks packet completeness

---

### Step 3: Hard Enforcement
**Trigger:** After 2 successful packet-compliant PRs  
**Action:** Enable `aiv-guard.yml` as required check

**GitHub Settings:**
1. Go to repo Settings ‚Üí Branches ‚Üí Branch protection rules for `main`
2. Add "AIV Packet Validation" to required status checks
3. Enable "Require status checks to pass before merging"

---

## Risk Mitigation

### Risk 1: CI Takes Too Long
**Mitigation:** 
- Run negative checks and schema validation only on labeled PRs
- Use matrix parallelization for multi-OS tests

### Risk 2: Packet Format Too Rigid
**Mitigation:**
- Allow "Fast-Track (Trivial)" exception for docs-only changes
- Accept "good faith" packets even if formatting is imperfect
- Focus on substance (evidence exists) over style (Markdown formatting)

### Risk 3: Verifier Friction (Compliance Overhead)
**Mitigation:**
- Keep packet template simple and copy-pasteable
- Don't require advanced tooling (`aiv-cli`) for this phase
- Allow verifiers to approve based on CI artifacts without deep cognitive work
- Defer Mental Trace and Ownership Lock requirements to future SVP phase

### Risk 4: False Sense of Security
**Mitigation:**
- Acknowledge that SOP compliance ‚â† perfect code quality
- SOP ensures evidence exists; human judgment still required
- Plan to add SVP cognitive layer after refactor work stabilizes

---

## Success Metrics

### Enforcement Quality (SOP Compliance)
- ‚úÖ 100% of PRs include verification packet (even if imperfect)
- ‚úÖ 90%+ of claims have CI artifact links (not just text assertions)
- ‚úÖ CI runtime matches target (Python 3.10+)
- ‚úÖ Class E links are immutable (commit SHAs, not `main` branch)

### Velocity (Minimal Friction)
- ‚è±Ô∏è PR review time <1h (verifier inspects artifacts, doesn't run code)
- ‚è±Ô∏è CI run time <10 min (parallelized)
- ‚è±Ô∏è Packet creation time <5 min (simple copy/paste template)

### Evidence Traceability
- üìä Every claim maps to at least one evidence class
- üìä No "trust me" assertions without CI backing
- üìä Verifier can audit evidence without local execution

### Future Metrics (SVP Phase - Not Measured Yet)
- ‚è∏Ô∏è Verifier skill growth (ELO rating)
- ‚è∏Ô∏è Mental Trace quality
- ‚è∏Ô∏è Cognitive debt prevention

---

## Appendix A: Example Packets by Task Type

### Example 1: Task 1.1 (Rename Package Directory)

```markdown
# AIV Verification Packet (v2.1)

## Claim(s)
- Renamed directory `flashcore-lib` to `flashcore`
- Updated all import paths to reference new directory name
- setup.py can now read VERSION file from correct location

## Evidence

### Class A (Execution Evidence)
- CI run: [link to main.yml run]
- Test output shows all imports resolve correctly

### Class B (Referential Evidence)
- Git diff: `flashcore-lib/` ‚Üí `flashcore/`
- setup.py line 34: `version=read('flashcore', 'VERSION')`

### Class C (Negative Evidence)
- Artifact: `no_flashcore_lib_references.txt` (grep shows 0 results)

### Class E (Intent Alignment)
- Task: `.taskmaster/tasks/task_001.md` (Subtask 1.1)
- PRD: `docs/PRD.md` Section 2.A (Nuclear Reactor Fix)

### Class F (Conservation Evidence)
- CI test suite: All 47 tests pass (no tests removed)

## Reproduction
View CI artifacts at [link]. Run `git diff main..HEAD -- flashcore*/` to see rename.
```

---

### Example 2: Task 4.5 (O(1) Scheduler Fix)

```markdown
# AIV Verification Packet (v2.1)

## Claim(s)
- Removed O(N) history replay loop from `compute_next_state`
- Scheduler now initializes FSRSCard from cached card state (O(1))
- Performance improvement: 500-review card now processes in <10ms (was ~250ms)

## Evidence

### Class A (Execution Evidence)
- Benchmark artifact: `benchmark_comparison.txt` shows 25x speedup
- CI run: [link to perf-benchmark.yml]

### Class B (Referential Evidence)
- `flashcore/scheduler.py:154-160` (deleted history loop)
- `flashcore/scheduler.py:162-167` (new cached state initialization)

### Class C (Negative Evidence)
- Artifact: `no_history_loops.txt` (grep for "for review in history" returns 0)

### Class E (Intent Alignment)
- Task: `.taskmaster/tasks/task_004.md` (Subtask 4.5)
- PRD: `docs/PRD.md` Section 2 Finding 2 (O(N) Performance Bug)

### Class F (Conservation Evidence)
- CI test suite: All scheduler tests pass
- New benchmark test added: `test_compute_next_state_is_constant_time`

## Reproduction
Download benchmark artifacts from CI. Compare baseline.json vs pr.json timings.
```

---

## Appendix B: Packet Template Generator (Optional Script)

Location: `scripts/generate_packet.py`

```python
#!/usr/bin/env python3
"""Generate AIV Packet template for a given task."""
import sys
import json

def generate_packet(task_id: str) -> str:
    # Read task from tasks.json
    with open('.taskmaster/tasks/tasks.json') as f:
        data = json.load(f)
    
    # Find task (simplified - assumes master wrapper)
    tasks = data.get('master', {}).get('tasks', [])
    task = next((t for t in tasks if t.get('id') == int(task_id)), None)
    
    if not task:
        return f"Error: Task {task_id} not found"
    
    template = f"""# AIV Verification Packet (v2.1)

## Claim(s)
<!-- {task['title']} -->
- 

## Evidence

### Class A (Execution Evidence)
- CI run: 

### Class B (Referential Evidence)
- 

### Class C (Negative Evidence)
- 

### Class D (State Evidence)
- N/A

### Class E (Intent Alignment)
- Task: `.taskmaster/tasks/task_{task_id:03d}.md`
- PRD: `docs/PRD.md#`

### Class F (Conservation Evidence)
- CI test suite: 

## Reproduction
<!-- Test strategy: {task.get('testStrategy', 'N/A')} -->
"""
    return template

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("Usage: python scripts/generate_packet.py <task_id>")
        sys.exit(1)
    
    print(generate_packet(sys.argv[1]))
```

---

## Document Maintenance

**Owner:** Project Lead  
**Review Cadence:** After every 5 PRs or when enforcement gaps are discovered  
**Version History:**
- v1.0 (2025-12-31): Initial enforcement plan for PR-2
- v1.1 (2025-12-31): Revised to focus on SOP compliance only; deferred SVP cognitive requirements

---

## Summary: What's Ready for PR-2

### ‚úÖ SOP Compliance Layer (Implemented)

This enforcement plan provides a **pragmatic, minimal-friction** approach for Tasks 1-9 refactor work:

**Hard Enforcement (Blocking):**
1. ‚úÖ **Packet Gating:** PRs must include verification packet with required sections
2. ‚úÖ **Immutable Intent Links:** Class E links must target commit SHAs, not mutable branches
3. ‚úÖ **CI-First Evidence:** Claims must point to CI runs or artifacts (not just text assertions)
4. ‚úÖ **Runtime Alignment:** CI runs on Python 3.10+ (matches project requirements)

**Soft Enforcement (Warnings Only):**
5. ‚ö†Ô∏è **Anti-Cheat Check:** Warns on deleted assertions/skipped tests (verifier judges if justified)
6. ‚ö†Ô∏è **Artifact Quality:** Encourages CI artifacts over local execution (but doesn't forbid local)

**Infrastructure Changes:**
- `.github/PULL_REQUEST_TEMPLATE.md`: Replace with AIV packet template
- `.github/workflows/aiv-guard.yml`: Validate packet structure + immutable links
- `.github/workflows/main.yml`: Fix Python version, add artifact uploads, add anti-cheat warning
- Optional: `.github/workflows/perf-benchmark.yml` for Task 4 performance claims

---

### ‚è∏Ô∏è SVP Cognitive Layer (Deferred to Future)

The following are **explicitly NOT required** for the refactor phase:

- ‚ùå Mental Trace documentation (verifiers not required to document cognitive simulation)
- ‚ùå Ownership Commits (verifiers not required to make semantic refactoring commits)
- ‚ùå Verifier ELO tracking (no skill measurement system)
- ‚ùå Advanced tooling (`aiv-cli`, automated packet generators)
- ‚ùå Strict Zero-Touch mandate (local execution discouraged but allowed)

**Rationale:** Focus resources on getting refactor work (Tasks 1-9) done with evidence-based verification. Add cognitive layer after infrastructure stabilizes.

---

### üéØ Success Criteria for PR-2

PR-2 is successful if:

1. **Packet validation works:** `aiv-guard.yml` correctly rejects PRs without packets
2. **Immutable links enforced:** `aiv-guard.yml` rejects mutable Class E links
3. **CI artifacts uploaded:** Test results, coverage, negative checks available as artifacts
4. **Python 3.10+ verified:** CI runs on correct Python version
5. **Anti-cheat warns:** Test weakening generates warning report (doesn't block)
6. **Low friction:** Implementers can create packets in <5 minutes via copy/paste

**Next Steps After PR-2:**
- Use this system for Tasks 1-9 refactor work
- Collect feedback on packet format and enforcement friction
- After refactor stabilizes, design SVP cognitive layer (Mental Trace, Ownership Lock)
- Build advanced tooling (`aiv-cli`) based on real usage patterns
